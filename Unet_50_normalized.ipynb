{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.utils.data as utils\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import cv2\n",
    "from torchmetrics import JaccardIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2020 Phil Wang\n",
    "https://github.com/lucidrains/byol-pytorch/\n",
    "\n",
    "Adjusted to de-couple for data loading, parallel training\n",
    "\"\"\"\n",
    "# BYOL for SSL training, not using yet.\n",
    "import copy\n",
    "import random\n",
    "from functools import wraps\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# helper functions\n",
    "\n",
    "\n",
    "def default(val, def_val):\n",
    "    return def_val if val is None else val\n",
    "\n",
    "\n",
    "def flatten(t):\n",
    "    return t.reshape(t.shape[0], -1)\n",
    "\n",
    "\n",
    "def singleton(cache_key):\n",
    "    def inner_fn(fn):\n",
    "        @wraps(fn)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            instance = getattr(self, cache_key)\n",
    "            if instance is not None:\n",
    "                return instance\n",
    "\n",
    "            instance = fn(self, *args, **kwargs)\n",
    "            setattr(self, cache_key, instance)\n",
    "            return instance\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return inner_fn\n",
    "\n",
    "\n",
    "# loss fn\n",
    "\n",
    "\n",
    "def loss_fn(x, y):\n",
    "    x = F.normalize(x, dim=-1, p=2)\n",
    "    y = F.normalize(y, dim=-1, p=2)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)\n",
    "\n",
    "\n",
    "# augmentation utils\n",
    "\n",
    "\n",
    "class RandomApply(nn.Module):\n",
    "    def __init__(self, fn, p):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if random.random() > self.p:\n",
    "            return x\n",
    "        return self.fn(x)\n",
    "\n",
    "\n",
    "# exponential moving average\n",
    "\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "\n",
    "def update_moving_average(ema_updater, ma_model, current_model):\n",
    "    for current_params, ma_params in zip(\n",
    "        current_model.parameters(), ma_model.parameters()\n",
    "    ):\n",
    "        old_weight, up_weight = ma_params.data, current_params.data\n",
    "        ma_params.data = ema_updater.update_average(old_weight, up_weight)\n",
    "\n",
    "\n",
    "# MLP class for projector and predictor\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, projection_size, hidden_size=4096):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size, projection_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# a wrapper class for the base neural network\n",
    "# will manage the interception of the hidden layer output\n",
    "# and pipe it into the projecter and predictor nets\n",
    "\n",
    "\n",
    "class NetWrapper(nn.Module):\n",
    "    def __init__(self, net, projection_size, projection_hidden_size, layer=-2):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.layer = layer\n",
    "\n",
    "        self.projector = None\n",
    "        self.projection_size = projection_size\n",
    "        self.projection_hidden_size = projection_hidden_size\n",
    "\n",
    "        self.hidden = None\n",
    "        self.hook_registered = False\n",
    "\n",
    "    def _find_layer(self):\n",
    "        if type(self.layer) == str:\n",
    "            modules = dict([*self.net.named_modules()])\n",
    "            return modules.get(self.layer, None)\n",
    "        elif type(self.layer) == int:\n",
    "            children = [*self.net.children()]\n",
    "            return children[self.layer]\n",
    "        return None\n",
    "\n",
    "    def _hook(self, _, __, output):\n",
    "        self.hidden = flatten(output)\n",
    "\n",
    "    def _register_hook(self):\n",
    "        layer = self._find_layer()\n",
    "        assert layer is not None, f\"hidden layer ({self.layer}) not found\"\n",
    "        handle = layer.register_forward_hook(self._hook)\n",
    "        self.hook_registered = True\n",
    "\n",
    "    @singleton(\"projector\")\n",
    "    def _get_projector(self, hidden):\n",
    "        _, dim = hidden.shape\n",
    "        projector = MLP(dim, self.projection_size, self.projection_hidden_size)\n",
    "        return projector.to(hidden)\n",
    "\n",
    "    def get_representation(self, x):\n",
    "        if not self.hook_registered:\n",
    "            self._register_hook()\n",
    "\n",
    "        if self.layer == -1:\n",
    "            return self.net(x)\n",
    "\n",
    "        _ = self.net(x)\n",
    "        hidden = self.hidden\n",
    "        self.hidden = None\n",
    "        assert hidden is not None, f\"hidden layer {self.layer} never emitted an output\"\n",
    "        return hidden\n",
    "\n",
    "    def forward(self, x):\n",
    "        representation = self.get_representation(x)\n",
    "        projector = self._get_projector(representation)\n",
    "        projection = projector(representation)\n",
    "        return projection\n",
    "\n",
    "\n",
    "# main class\n",
    "\n",
    "\n",
    "class BYOL(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        net,\n",
    "        image_size,\n",
    "        hidden_layer=-2,\n",
    "        projection_size=256,\n",
    "        projection_hidden_size=4096,\n",
    "        augment_fn=None,\n",
    "        moving_average_decay=0.99,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.online_encoder = NetWrapper(\n",
    "            net, projection_size, projection_hidden_size, layer=hidden_layer\n",
    "        )\n",
    "        self.target_encoder = None\n",
    "        self.target_ema_updater = EMA(moving_average_decay)\n",
    "\n",
    "        self.online_predictor = MLP(\n",
    "            projection_size, projection_size, projection_hidden_size\n",
    "        )\n",
    "\n",
    "        # send a mock image tensor to instantiate singleton parameters\n",
    "        self.forward(torch.randn(2, 3, image_size, image_size), torch.randn(2, 3, image_size, image_size))\n",
    "\n",
    "    @singleton(\"target_encoder\")\n",
    "    def _get_target_encoder(self):\n",
    "        target_encoder = copy.deepcopy(self.online_encoder)\n",
    "        return target_encoder\n",
    "\n",
    "    def reset_moving_average(self):\n",
    "        del self.target_encoder\n",
    "        self.target_encoder = None\n",
    "\n",
    "    def update_moving_average(self):\n",
    "        assert (\n",
    "            self.target_encoder is not None\n",
    "        ), \"target encoder has not been created yet\"\n",
    "        update_moving_average(\n",
    "            self.target_ema_updater, self.target_encoder, self.online_encoder\n",
    "        )\n",
    "\n",
    "    def forward(self, image_one, image_two):\n",
    "        online_proj_one = self.online_encoder(image_one)\n",
    "        online_proj_two = self.online_encoder(image_two)\n",
    "\n",
    "        online_pred_one = self.online_predictor(online_proj_one)\n",
    "        online_pred_two = self.online_predictor(online_proj_two)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            target_encoder = self._get_target_encoder()\n",
    "            target_proj_one = target_encoder(image_one)\n",
    "            target_proj_two = target_encoder(image_two)\n",
    "\n",
    "        loss_one = loss_fn(online_pred_one, target_proj_two.detach())\n",
    "        loss_two = loss_fn(online_pred_two, target_proj_one.detach())\n",
    "\n",
    "        loss = loss_one + loss_two\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "# Unet basic model structures.\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Helper module that consists of a Conv -> BN -> ReLU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.with_nonlinearity = with_nonlinearity\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.with_nonlinearity:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bridge(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the middle layer of the UNet which just consists of some\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.bridge = nn.Sequential(\n",
    "            ConvBlock(in_channels, out_channels),\n",
    "            ConvBlock(out_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bridge(x)\n",
    "\n",
    "\n",
    "class UpBlockForUNetWithResNet50(nn.Module):\n",
    "    \"\"\"\n",
    "    Up block that encapsulates one up-sampling step which consists of Upsample -> ConvBlock -> ConvBlock\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n",
    "                 upsampling_method=\"conv_transpose\"):\n",
    "        super().__init__()\n",
    "\n",
    "        if up_conv_in_channels == None:\n",
    "            up_conv_in_channels = in_channels\n",
    "        if up_conv_out_channels == None:\n",
    "            up_conv_out_channels = out_channels\n",
    "\n",
    "        if upsampling_method == \"conv_transpose\":\n",
    "            self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n",
    "        elif upsampling_method == \"bilinear\":\n",
    "            self.upsample = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "            )\n",
    "        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n",
    "        self.conv_block_2 = ConvBlock(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, up_x, down_x):\n",
    "        \"\"\"\n",
    "\n",
    "        :param up_x: this is the output from the previous up block\n",
    "        :param down_x: this is the output from the down block\n",
    "        :return: upsampled feature map\n",
    "        \"\"\"\n",
    "        x = self.upsample(up_x)\n",
    "        x = torch.cat([x, down_x], 1)\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetWithResnet50Encoder(nn.Module):\n",
    "    DEPTH = 6\n",
    "\n",
    "    def __init__(self, n_classes=49):\n",
    "        super().__init__()\n",
    "#         byol_model = torch.load('/home/yz10727/data/best_model_SSL_1.pth')\n",
    "#         resnet=byol_model.target_encoder.net\n",
    "#         resnet.requires_grad = False\n",
    "        resnet = models.resnet50(weights=None)\n",
    "#         resnet = torch.load('/scratch/yz10727/data/Pre_resnet50.pth')\n",
    "#         for param in resnet.parameters():\n",
    "#                 param.requires_grad = False\n",
    "#         resnet_up = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        down_blocks = []\n",
    "        up_blocks = []\n",
    "        self.input_block = nn.Sequential(*list(resnet.children()))[:3]\n",
    "        self.input_pool = list(resnet.children())[3]\n",
    "        for bottleneck in list(resnet.children()):\n",
    "            if isinstance(bottleneck, nn.Sequential):\n",
    "                down_blocks.append(bottleneck)\n",
    "        self.down_blocks = nn.ModuleList(down_blocks)\n",
    "        self.bridge = Bridge(2048, 2048)\n",
    "        \n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(2048, 1024))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(1024, 512))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(512, 256))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=128 + 64, out_channels=128,\n",
    "                                                    up_conv_in_channels=256, up_conv_out_channels=128))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=64 + 3, out_channels=64,\n",
    "                                                    up_conv_in_channels=128, up_conv_out_channels=64))\n",
    "\n",
    "        self.up_blocks = nn.ModuleList(up_blocks)\n",
    "\n",
    "        self.out = nn.Conv2d(64, n_classes, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x, with_output_feature_map=False):\n",
    "        pre_pools = dict()\n",
    "        pre_pools[f\"layer_0\"] = x\n",
    "        x = self.input_block(x)\n",
    "        pre_pools[f\"layer_1\"] = x\n",
    "        x = self.input_pool(x)\n",
    "        #################UPDATE######################\n",
    "#         with torch.no_grad():\n",
    "        for i, block in enumerate(self.down_blocks, 2):\n",
    "            x = block(x)\n",
    "            if i == (UNetWithResnet50Encoder.DEPTH - 1):\n",
    "                continue\n",
    "            pre_pools[f\"layer_{i}\"] = x\n",
    "\n",
    "        x = self.bridge(x)\n",
    "        #############END UPDATE######################\n",
    "        for i, block in enumerate(self.up_blocks, 1):\n",
    "            key = f\"layer_{UNetWithResnet50Encoder.DEPTH - 1 - i}\"\n",
    "            x = block(x, pre_pools[key])\n",
    "        output_feature_map = x\n",
    "        x = self.out(x)\n",
    "        del pre_pools\n",
    "        if with_output_feature_map:\n",
    "            return x, output_feature_map\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "import os\n",
    "from data import UnlabeledDataset,LabeledDataset,ValidationDataset\n",
    "# Load the data with Daniel's data.py\n",
    "\n",
    "dataset = LabeledDataset('/scratch/py2050/Dataset_Student/')\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, num_workers=1)\n",
    "\n",
    "val_dataset = ValidationDataset('/scratch/py2050/Dataset_Student/')\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=2, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNetWithResnet50Encoder(n_classes=49).to(device)\n",
    "# model = torch.load('best_model_unet_50.pth') for restart training, remember to modify\n",
    "criterion = criterion = nn.CrossEntropyLoss()\n",
    "# parameter chosen from YOLOv8 default value.\n",
    "optim = Adam(model.parameters(), lr=0.0003,weight_decay=0.0001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40 # num of epochs, modify based on node time\n",
    "best_train_acc = 1\n",
    "best_val_acc = 0  #Use IOU \n",
    "jaccard = JaccardIndex(task=\"multiclass\", num_classes=49).to(device)  \n",
    "model_path = '/scratch/py2050/best_model_unet_50.pth' # your model path, remember to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 221/500 [10:48<13:15,  2.85s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print(\"Training epoch: \", epoch)\n",
    "    train_loss = 0   \n",
    "    val_IoU_accuracy = 0 \n",
    "    model.train()\n",
    "\n",
    "    for data in tqdm(train_dataloader): \n",
    "        input, label = data\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        input = input.reshape(-1,input.shape[2],input.shape[3],input.shape[4])\n",
    "        label = label.reshape(-1,label.shape[2],label.shape[3])\n",
    "        outputs = model(input)\n",
    "        outputs = F.interpolate(outputs, size=(160, 240), mode='bilinear', align_corners=False)\n",
    "        loss = criterion(outputs, label.long())\n",
    "        loss.backward()   \n",
    "        optim.step()                                               \n",
    "        optim.zero_grad()                                           \n",
    "        train_loss += loss.item()  \n",
    "#         break\n",
    "    train_loss /= (len(train_dataloader.dataset) * 22)   \n",
    "    \n",
    "    print(\"Validating epoch: \", epoch)\n",
    "    for idx, data in enumerate(tqdm(val_dataloader)):\n",
    "#         print(idx)\n",
    "        val_input, val_label = data\n",
    "        input, label = val_input.to(device), val_label.to(device)\n",
    "        input = input.reshape(-1,input.shape[2],input.shape[3],input.shape[4])\n",
    "        label = label.reshape(-1,label.shape[2],label.shape[3])\n",
    "        outputs = model(input)\n",
    "        outputs = F.interpolate(outputs, size=(160, 240), mode='bilinear', align_corners=False)\n",
    "        output = nn.LogSoftmax()(outputs)\n",
    "        output = torch.argmax(output, dim=1)\n",
    "#         print(output.shape, label.shape)\n",
    "        for i in range(label.shape[0]):\n",
    "#             print(output[i].squeeze(0).shape, output[i].shape)\n",
    "            jac = jaccard(output[i], label[i].to(device))\n",
    "            val_IoU_accuracy += jac\n",
    "        if idx == 49: # shorten val time, val on 22*50*2 images\n",
    "            break\n",
    "    val_IoU_accuracy /= (22*50*2)  # remember to modify based on sample val length\n",
    "    \n",
    "    print(\"Epoch{}: Training Loss:{:.6f}; Val IoU: {:.6f}.\\n\".format(epoch, train_loss, val_IoU_accuracy))\n",
    "    if best_val_acc < val_IoU_accuracy:\n",
    "        best_val_acc = val_IoU_accuracy\n",
    "        torch.save(model, model_path)  \n",
    "        print('Best model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('/scratch/py2050/best_model_unet_50.pth') # currently istrained 50-class model, remember to modify\n",
    "\n",
    "num_check = 50 # video index to display, choose from 0~999\n",
    "frame_check = 1 # frame index to display, choose from 0~21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = dataset[num_check][0][frame_check].unsqueeze(0)\n",
    "input = input.to(device)\n",
    "\n",
    "# print(dataset[num_check][0][frame_check][0][159])\n",
    "\n",
    "output = model(input) \n",
    "outputs = nn.LogSoftmax()(output)\n",
    "outputs = torch.argmax(outputs, dim=1)\n",
    "outputs = transforms.Resize((160, 240), interpolation=transforms.InterpolationMode.NEAREST)(outputs)\n",
    "print(outputs.shape)\n",
    "\n",
    "outputs=outputs.squeeze(0).cpu().numpy()\n",
    "print(outputs.shape)\n",
    "plt.imshow(outputs)\n",
    "plt.axis('off')  \n",
    "plt.title('Predicted unresized Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = dataset[num_check][0][frame_check]\n",
    "input = transforms.Resize((160, 240), interpolation=transforms.InterpolationMode.NEAREST)(input)\n",
    "\n",
    "plt.imshow(input.permute(1, 2, 0))\n",
    "plt.axis('off')  \n",
    "plt.title('Actual unresized Normalized Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_truth_label = dataset[num_check][1][frame_check]\n",
    "\n",
    "plt.imshow(input_truth_label)\n",
    "plt.axis('off')  \n",
    "plt.title('Ground Truth Label Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac = jaccard(torch.Tensor(outputs).to(device), torch.Tensor(input_truth_label).to(device))\n",
    "jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
